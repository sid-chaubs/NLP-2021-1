{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "canadian-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score,classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pandas import DataFrame\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "significant-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"SemEval2018-Task3/datasets/goldtest_TaskB/SemEval2018-T3_gold_test_taskB_emoji.txt\",sep='\\t',header=0,index_col=0,quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "test_set_true_label = test_set['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "crazy-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisiondf = DataFrame()\n",
    "f1df= DataFrame()\n",
    "recalldf = DataFrame()\n",
    "accuracydf= DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "innovative-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    random_label = np.random.randint(0,4,size=len(test_set_true_label))\n",
    "    precision = precision_score(test_set_true_label, random_label,labels=[0,1,2,3], average=None)\n",
    "    recall = recall_score(test_set_true_label, random_label, labels=[0,1,2,3],average=None)\n",
    "    f1 = f1_score(test_set_true_label, random_label, labels=[0,1,2,3],average=None)\n",
    "    random_confusion_matrix = confusion_matrix(test_set_true_label, random_label, labels=[0, 1, 2, 3])\n",
    "    random_confusion_matrix = random_confusion_matrix.astype('float') / random_confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    accuracy = random_confusion_matrix.diagonal()\n",
    "    precisiondf = precisiondf.append(pd.Series(precision), ignore_index=True)\n",
    "    recalldf = recalldf.append(pd.Series(recall), ignore_index=True)\n",
    "    f1df = f1df.append(pd.Series(f1), ignore_index=True)\n",
    "    accuracydf = accuracydf.append(pd.Series(accuracy), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "atmospheric-monte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Class 0: 0.24955602536997887, Class 1: 0.25640243902439025, Class 2: 0.2551764705882353, Class 3: 0.25903225806451613\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for Class 0: {}, Class 1: {}, Class 2: {}, Class 3: {}\".format( mean(list(accuracydf[0])), mean(list(accuracydf[1])), mean(list(accuracydf[2])), mean(list(accuracydf[3])) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "whole-fisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score for Class 0: 0.6024725981994518, Class 1: 0.21403249825787665, Class 2: 0.11098074800367425, Class 3: 0.08170271111387295\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision Score for Class 0: {}, Class 1: {}, Class 2: {}, Class 3: {}\".format( mean(list(precisiondf[0])), mean(list(precisiondf[1])), mean(list(precisiondf[2])), mean(list(precisiondf[3])) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "covered-working",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score for Class 0: 0.24955602536997887, Class 1: 0.25640243902439025, Class 2: 0.2551764705882353, Class 3: 0.25903225806451613\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score for Class 0: {}, Class 1: {}, Class 2: {}, Class 3: {}\".format( mean(list(recalldf[0])), mean(list(recalldf[1])), mean(list(recalldf[2])), mean(list(recalldf[3])) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "advisory-reach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Class 0: 0.3526875300002713, Class 1: 0.23309499789936308, Class 2: 0.15457234434897685, Class 3: 0.12413299382351782\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score for Class 0: {}, Class 1: {}, Class 2: {}, Class 3: {}\".format( mean(list(f1df[0])), mean(list(f1df[1])), mean(list(f1df[2])), mean(list(f1df[3])) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "dirty-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy macro average: 0.25504179826178014\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy macro average: {}\".format((mean(list(accuracydf[0]))+ mean(list(accuracydf[1]))+ mean(list(accuracydf[2]))+mean(list(accuracydf[3])))/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "uniform-suicide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision macro average: 0.25229713889371885\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision macro average: {}\".format((mean(list(precisiondf[0]))+ mean(list(precisiondf[1]))+ mean(list(precisiondf[2]))+mean(list(precisiondf[3])))/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "closing-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall macro average: 0.25504179826178014\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall macro average: {}\".format((mean(list(recalldf[0]))+ mean(list(recalldf[1]))+ mean(list(recalldf[2]))+mean(list(recalldf[3])))/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "quarterly-terry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 macro average: 0.21612196651803225\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 macro average: {}\".format((mean(list(f1df[0]))+ mean(list(f1df[1]))+ mean(list(f1df[2]))+mean(list(f1df[3])))/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "plain-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    60.331633\n",
      "1    20.918367\n",
      "2    10.841837\n",
      "3     7.908163\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(test_set.groupby(test_set['Label']).size()/len(test_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy weighted average: {}\".format((mean(list(accuracydf[0]))+ mean(list(accuracydf[1]))+ mean(list(accuracydf[2]))+mean(list(accuracydf[3])))/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision weighted average: {}\".format((mean(list(precisiondf[0]))+ mean(list(precisiondf[1]))+ mean(list(precisiondf[2]))+mean(list(precisiondf[3])))/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall weighted average: {}\".format((mean(list(recalldf[0]))+ mean(list(recalldf[1]))+ mean(list(recalldf[2]))+mean(list(recalldf[3])))/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 weighted average: {}\".format((mean(list(f1df[0]))+ mean(list(f1df[1]))+ mean(list(f1df[2]))+mean(list(f1df[3])))/4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
